{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.29-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
      "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
      "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.48-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.7.0-py3-none-any.whl.metadata (103 kB)\n",
      "     ---------------------------------------- 0.0/103.4 kB ? eta -:--:--\n",
      "     --------------- ------------------------ 41.0/103.4 kB ? eta -:--:--\n",
      "     -------------------------------------- 103.4/103.4 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.21.1-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.1-cp312-none-win_amd64.whl.metadata (50 kB)\n",
      "     ---------------------------------------- 0.0/50.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 50.9/50.9 kB ? eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.18.1 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.18.1-cp312-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
      "   ---------------------------------------- 0.0/817.7 kB ? eta -:--:--\n",
      "   ------------------------- ------------- 542.7/817.7 kB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 817.7/817.7 kB 13.0 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "   ---------------------------------------- 0.0/369.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 369.0/369.0 kB 22.4 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.9 MB 20.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.3/1.9 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/1.9 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.9/1.9 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/1.9 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.3/1.9 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.7/1.9 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.8/1.9 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 3.0 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
      "   ---------------------------------------- 0.0/290.2 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 30.7/290.2 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 235.5/290.2 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 290.2/290.2 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading langsmith-0.1.48-py3-none-any.whl (113 kB)\n",
      "   ---------------------------------------- 0.0/113.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 113.7/113.7 kB 6.9 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Downloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "   ---------------------------------------- 0.0/407.9 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 122.9/407.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 407.9/407.9 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.1-cp312-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.1/1.9 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.9/1.9 MB 19.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 15.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 12.2 MB/s eta 0:00:00\n",
      "Using cached PyYAML-6.0.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "Downloading SQLAlchemy-2.0.29-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.6/2.1 MB 18.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.0/2.1 MB 13.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.6/2.1 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 11.0 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Downloading greenlet-3.0.3-cp312-cp312-win_amd64.whl (293 kB)\n",
      "   ---------------------------------------- 0.0/293.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 293.6/293.6 kB 18.9 MB/s eta 0:00:00\n",
      "Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.4/49.4 kB 1.3 MB/s eta 0:00:00\n",
      "Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n",
      "Downloading orjson-3.10.1-cp312-none-win_amd64.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 139.2/139.2 kB 4.2 MB/s eta 0:00:00\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: tenacity, PyYAML, pydantic-core, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, greenlet, frozenlist, annotated-types, yarl, typing-inspect, SQLAlchemy, pydantic, marshmallow, jsonpatch, aiosignal, langsmith, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.29 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.6.0 dataclasses-json-0.6.4 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.33 langchain-core-0.1.44 langchain-text-splitters-0.0.1 langsmith-0.1.48 marshmallow-3.21.1 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.1 packaging-23.2 pydantic-2.7.0 pydantic-core-2.18.1 tenacity-8.2.3 typing-inspect-0.9.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "#Installation\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-openai\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain-openai) (0.1.44)\n",
      "Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n",
      "  Downloading openai-1.21.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting tiktoken<1,>=0.5.2 (from langchain-openai)\n",
      "  Downloading tiktoken-0.6.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.1.48)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.7.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (8.2.3)\n",
      "Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.10.0->langchain-openai)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.11.0)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.5.2->langchain-openai)\n",
      "  Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.0/42.0 kB ? eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai)\n",
      "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.42->langchain-openai) (3.10.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.10.0->langchain-openai) (0.4.6)\n",
      "Downloading langchain_openai-0.1.3-py3-none-any.whl (33 kB)\n",
      "Downloading openai-1.21.2-py3-none-any.whl (309 kB)\n",
      "   ---------------------------------------- 0.0/309.9 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 112.6/309.9 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 174.1/309.9 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 309.9/309.9 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading tiktoken-0.6.0-cp312-cp312-win_amd64.whl (798 kB)\n",
      "   ---------------------------------------- 0.0/798.3 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 112.6/798.3 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 450.6/798.3 kB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 798.3/798.3 kB 6.3 MB/s eta 0:00:00\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "   ---------------------------------------- 0.0/77.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 77.9/77.9 kB ? eta 0:00:00\n",
      "Downloading regex-2024.4.16-cp312-cp312-win_amd64.whl (268 kB)\n",
      "   ---------------------------------------- 0.0/268.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 268.4/268.4 kB 17.2 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, httpcore, distro, anyio, tiktoken, httpx, openai, langchain-openai\n",
      "Successfully installed anyio-4.3.0 distro-1.9.0 httpcore-1.0.5 httpx-0.27.0 langchain-openai-0.1.3 openai-1.21.2 regex-2024.4.16 tiktoken-0.6.0 tqdm-4.66.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# OPENAI_API_KEY=os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# !export OPENAI_API_KEY=\"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화\n",
    "\n",
    "# OpenAI (API)\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI()  # ChatOpenAI(api_key=\"...\")\n",
    "\n",
    "# # Local (using Ollama)\n",
    "# # https://ollama.com/download 에서 OS에 맞는 Ollama 다운로드\n",
    "# # 터미널에서 `ollama run llama2` 입력 (llama2 설치/실행)\n",
    "# from langchain_community.llms import Ollama\n",
    "# llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in several ways:\\n\\n1. Automated testing: Langsmith can be used to write scripts and automate the testing process, making it faster and more efficient.\\n\\n2. Test case generation: Langsmith can be used to generate test cases based on specifications and requirements, ensuring thorough coverage of the application.\\n\\n3. Test data generation: Langsmith can help in generating test data for different scenarios, making it easier to test the application under various conditions.\\n\\n4. Integration testing: Langsmith can be used to test the integration of different components of the application, ensuring that they work together seamlessly.\\n\\n5. Performance testing: Langsmith can be used to conduct performance testing to evaluate the speed, responsiveness, and stability of the application under different load conditions.\\n\\nOverall, Langsmith can help streamline the testing process, improve test coverage, and ensure the quality of the software product.', response_metadata={'token_usage': {'completion_tokens': 176, 'prompt_tokens': 15, 'total_tokens': 191}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-496d6915-6572-4070-ad63-fbf98a2f3a40-0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# prompt template로 원하는 응답을 유도 \n",
    "# Prompt templates은 사용자의 입력을 LLM에게 더 나은 입력으로 변환\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt와 llm 모델을 간단한 LLM chain으로 변합\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith is a powerful tool that can greatly assist with testing in various ways. Here are some ways in which Langsmith can help with testing:\\n\\n1. **Test data generation**: Langsmith can be used to generate realistic and diverse test data quickly and easily. This can help in creating a comprehensive set of test cases to validate the functionality and performance of the system under test.\\n\\n2. **Test case automation**: Langsmith can automate the generation of test cases based on predefined rules and constraints. This can save time and effort in creating and maintaining test cases for regression testing or new feature testing.\\n\\n3. **Test environment setup**: Langsmith can help in setting up test environments by automatically generating configuration files, database schemas, and other resources needed for testing. This can streamline the process of preparing test environments and reduce the chances of errors in configuration.\\n\\n4. **Test coverage analysis**: Langsmith can analyze the coverage of test cases and identify gaps in testing. This can help in ensuring that all critical parts of the system are adequately tested and that potential risks are mitigated.\\n\\n5. **Test result analysis**: Langsmith can analyze test results and provide insights into the performance and behavior of the system under test. This can help in identifying issues and bottlenecks that need to be addressed to improve the overall quality of the software.\\n\\nOverall, Langsmith can be a valuable tool in the testing process, helping testers to be more efficient, thorough, and effective in validating the quality of the software.', response_metadata={'token_usage': {'completion_tokens': 297, 'prompt_tokens': 27, 'total_tokens': 324}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-d389d312-e794-439d-94c8-f715299b885f-0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 출력 chat message를 string으로 변환하는 간단한 parser 추가\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can be a valuable tool for testing in several ways:\\n\\n1. Automated testing: Langsmith can be used to automate testing processes, such as running test scripts and generating test reports. This can help ensure that the software is functioning as expected and that any bugs or issues are identified and addressed promptly.\\n\\n2. Test data generation: Langsmith can help generate realistic and diverse test data for various scenarios, making it easier to test the software under different conditions and edge cases.\\n\\n3. Performance testing: Langsmith can be used to simulate high traffic loads and test the performance of the software under stress. This can help identify any bottlenecks or performance issues that need to be addressed.\\n\\n4. Integration testing: Langsmith can be used to test the integration of different components or systems, ensuring that they work together seamlessly and without any compatibility issues.\\n\\nOverall, Langsmith can streamline the testing process, improve test coverage, and help identify and resolve issues early in the development cycle.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval는 LLM에 직접 넣기에는 데이터가 너무 많을 때 유용합니다. Retriever를 사용해서 가장 관련있는 부분만 가져와서 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents, Embeddings, VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# 참조할 데이터를 로드\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/user_guide\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 모델\n",
    "# 문서를 임베딩해서 vectorstores에 저장하는 모델\n",
    "\n",
    "# OpenAI (API)\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "# # Local (using Ollama)\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "# embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.8.0-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\r2com\\desktop\\kpopmap\\.venv\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Downloading faiss_cpu-1.8.0-cp312-cp312-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB 325.1 kB/s eta 0:00:45\n",
      "   ---------------------------------------- 0.1/14.5 MB 751.6 kB/s eta 0:00:20\n",
      "    --------------------------------------- 0.3/14.5 MB 2.1 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.7/14.5 MB 3.3 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.1/14.5 MB 4.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 5.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 5.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.6/14.5 MB 6.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.9/14.5 MB 6.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.3/14.5 MB 7.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.8/14.5 MB 7.2 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.1/14.5 MB 7.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.4/14.5 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.5/14.5 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.6/14.5 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.7/14.5 MB 6.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.9/14.5 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.2/14.5 MB 6.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.6/14.5 MB 6.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 6.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.2/14.5 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.2/14.5 MB 6.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.5/14.5 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.7/14.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.0/14.5 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.3/14.5 MB 5.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.5/14.5 MB 5.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.6/14.5 MB 5.6 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.7/14.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.0/14.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.3/14.5 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 5.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.7/14.5 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.9/14.5 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.1/14.5 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.3/14.5 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.6/14.5 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.8/14.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.3/14.5 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.6/14.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.4/14.5 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.5/14.5 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.7/14.5 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.8/14.5 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.0/14.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.4/14.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.7/14.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.5/14.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.5/14.5 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.7/14.5 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 5.2 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0\n"
     ]
    }
   ],
   "source": [
    "# 단순한 local vectorstore FAISS(Facebook AI Similarity Search)\n",
    "# https://python.langchain.com/docs/integrations/vectorstores/faiss/\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 색인 생성\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# # RecursiveCharacterTextSplitter 분할기는 청크가 충분히 작아질 때까지 주어진 문자 목록의 순서대로 텍스트를 분할하려고 시도합니다.\n",
    "# # 기본 문자 목록은 [\"\\n\\n\", \"\\n\", \" \", \"\"]입니다. 단락 -> 문장 -> 단어 순서로 재귀적으로 분할합니다.\n",
    "# text_splitter = RecursiveCharacterTextSplitter(\n",
    "#     # 청크 크기를 매우 작게 설정합니다. 예시를 위한 설정입니다.\n",
    "#     chunk_size=250,\n",
    "#     # 청크 간의 중복되는 문자 수를 설정합니다.\n",
    "#     chunk_overlap=50,\n",
    "#     # 문자열 길이를 계산하는 함수를 지정합니다.\n",
    "#     length_function=len,\n",
    "#     # 구분자로 정규식을 사용할지 여부를 설정합니다.\n",
    "#     is_separator_regex=False,\n",
    "# )\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = FAISS.from_documents(documents, embeddings) # 문서와 임베딩을 통해 생성된 백터스토어"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력된 질문을 받아, 관련된 문서를 찾고, 원래 질문과 함께 해당 문서를 LLM에 전달합니다.<br/>그래서 원래 질문에 대한 답변을 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "\"\"\"Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 문서 목록을 모델에 전달하는 chain\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can help by allowing users to visualize test results.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서를 직접 입력해서 실행시킬 수 있음\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_chain.invoke({\n",
    "    \"input\": \"how can langsmith help with testing?\",\n",
    "    \"context\": [Document(page_content=\"langsmith can let you visualize test results\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "# 가장 연관된 문서를 선택하기 위해 탐색기를 사용\n",
    "retriever = vector.as_retriever()\n",
    "\n",
    "# 질문과 탐색된 문서를 받아 답변을 생성하는 chain\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith can help with testing by allowing developers to create datasets, run tests on LLM applications using these datasets, upload test cases in bulk, create test cases on the fly, export test cases from application traces, and run custom evaluations to score test results. Additionally, LangSmith provides a comparison view to track and diagnose regressions in test scores across multiple revisions of an application, a playground environment for rapid iteration and experimentation, and the ability to add runs as examples to datasets to expand test coverage on real-world scenarios.\n"
     ]
    }
   ],
   "source": [
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "# 질문 -> retriever: 연관된 문서 검색 -> 모델에 질문과 연관된 문서 전달 -> 답변 생성\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
